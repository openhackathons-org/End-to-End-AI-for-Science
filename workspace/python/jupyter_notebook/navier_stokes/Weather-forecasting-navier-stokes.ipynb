{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting Weather using Navier Stokes PDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will solve the Navier Stokes PDE thereby predicting the weather pattern at the sea level. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contents of the Notebook\n",
    "\n",
    "- [Forecasting Weather using Navier Stokes PDE](#Forecasting-Weather-using-Navier-Stokes-PDE)\n",
    "    - [Problem Description](#Problem-Description)\n",
    "    - [Case Setup](#Case-Setup)\n",
    "    - [Step 1: Creating the geometry](#Step-1:-Creating-the-geometry)\n",
    "    - [Step 2: Defining the PDEs and creating the nodes.](#Step-2:-Defining-the-PDEs-and-creating-the-nodes.)\n",
    "    - [Step 3: Setting up the Domain: Assigning the boundary and PDE constraints](#Step-3:-Setting-up-the-Domain:-Assigning-the-boundary-and-PDE-constraints)\n",
    "    - [Step 4: Adding Inferencer data](#Step-4:-Adding-Inferencer-data)\n",
    "    - [Step 5: Hydra configuration](#Step-5:-Hydra-configuration)\n",
    "    - [Step 6: Putting everything together: Solver and training](#Step-6:-Putting-everything-together:-Solver-and-training)\n",
    "    - [Visualizing the solution](#Visualizing-the-solution)\n",
    "    - [Conclusion](#Conclusion)\n",
    "\n",
    "#### Learning Outcomes\n",
    "- How to use the inbuilt PDE equations present as part of Modulus.\n",
    "- How to scaling and nondimensionalizing techniques to solve the Problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting Weather using Navier Stokes PDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Description\n",
    "\n",
    "We aim to predict the velocities for 6-hour timesteps using the Navier-Stokes equation. For this, we use the Navier-Stokes equation. The Navierâ€“Stokes equations mathematically express the conservation of momentum and conservation of mass for Newtonian fluids. We will take a 2d projected input from the ERA5 Reanalysis dataset to be used as initial conditions for our input. We will look into the ERA5 dataset in detail in the upcoming notebooks. The process of taking the 3D sphere and projecting it onto a 2D mesh is shown in the diagram below, the 2D mesh is of the size (1440,720)\n",
    "\n",
    "\n",
    "<center><img src=\"images/projection.png\" alt=\"Drawing\" style=\"width: 600px;\"/></center>\n",
    "\n",
    "#### Navier-Stokes Equation \n",
    " \n",
    "The Navier-Stokes equations consist of a time-dependent continuity equation for the conservation of mass, three time-dependent conservation of momentum equations and a time-dependent conservation of energy equation. There are four independent variables in the problem, the $x$, $y$, and $z$ spatial coordinates of some domain, and the time $t$. There are six dependent variables; the pressure $p$, density $r$, and temperature $T$, and three components of the velocity vector; the $u$ component is in the $x$ direction, the $v$ component is in the $y$ direction, and the $w$ component is in the $z$ direction, All of the dependent variables are functions of all four independent variables.\n",
    " \n",
    "\n",
    "\\begin{equation}\n",
    "Continuity : \\frac{\\partial \\rho}{\\partial t} + \\overrightarrow{\\nabla}\\cdot(\\rho\\overrightarrow{u})=0 \\end{equation}\n",
    "\\begin{equation}\n",
    "Momentum : \\frac{\\partial(\\rho \\overrightarrow{u})}{\\partial t} + \\overrightarrow{\\nabla}\\cdot[\\rho\\overline{\\overline{u\\otimes u}}] = -\\overrightarrow{\\nabla p} + \\overrightarrow{\\nabla}\\cdot\\overline{\\overline{\\tau}} + \\rho\\overrightarrow{f} \\end{equation}\n",
    "\\begin{equation}\n",
    "Energy : \\frac{\\partial(\\rho e)}{\\partial t} + \\overrightarrow{\\nabla}\\cdot((\\rho e + p)\\overrightarrow{u}) = \\overrightarrow{\\nabla}\\cdot(\\overline{\\overline{\\tau}}\\cdot\\overrightarrow{u}) + \\rho\\overrightarrow{f}\\overrightarrow{u} + \\overrightarrow{\\nabla}\\cdot(\\overrightarrow{\\dot{q}})+r \\end{equation}\n",
    "\n",
    "We will now use the Navier-Stokes PDE to solve this problem statement to predict the flow using the below stated approximation. \n",
    "\n",
    "**Kindly note** : \n",
    "\n",
    "A Numerical weather prediction system uses different numerical methods, like the Finite Element method, to solve the following equations: \n",
    "- Momentum equations\n",
    "- Thermodynamic equation\n",
    "- Moisture equation\n",
    "- Continuity equation\n",
    "- Hydrostatic equation\n",
    "\n",
    "In our case, we use the Navier-Stokes equation, which conserves the following equations: \n",
    "- Momentum equations\n",
    "- Continuity equation\n",
    "\n",
    "**We follow this approach given the constraints of the bootcamp environment. Hence we do not compare the results with Numerical weather prediction in this case, but we will look into a more robust model going forward in the Data-driven approach and use it to predict the weather forecast and compare with the results from the dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Setup\n",
    "\n",
    "Now, let's start solving the problem by importing the required libraries and packages\n",
    "\n",
    "#### Note : In this notebook we will describe the contents of the [`navier_stokes.py`](../../source_code/navier_stokes/navier_stokes.py) script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "from sympy import Symbol, Eq, Abs, sin, cos\n",
    "\n",
    "import modulus\n",
    "from modulus.sym.hydra import to_absolute_path, instantiate_arch, ModulusConfig\n",
    "from modulus.sym.eq.pdes.navier_stokes import NavierStokes\n",
    "from modulus.sym.geometry.primitives_2d import Rectangle as rect\n",
    "from modulus.sym.models.fully_connected import FullyConnectedArch\n",
    "from modulus.sym.key import Key\n",
    "from modulus.sym.node import Node\n",
    "from modulus.sym.solver import Solver\n",
    "from modulus.sym.domain import Domain\n",
    "from modulus.sym.domain.constraint import (\n",
    "    PointwiseConstraint,\n",
    "    PointwiseInteriorConstraint,\n",
    ")\n",
    "from modulus.sym.domain.inferencer import PointVTKInferencer\n",
    "from modulus.sym.utils.io import (\n",
    "    VTKUniformGrid,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Creating the geometry\n",
    "\n",
    "In this problem, we will create the 2-dimensional periodic mesh using `Rectangle` class from the geometry module. We will define the 2-dimensional mesh object using the two end-points. While the input as defined in the problem statement is $(1440,720)$ , we will then pad the y-axis such that we have a periodic geometry, we do this because, we are representing a approximation of the flow in a 2D space by creating a periodic mesh, we try to address the problem to a certain extent by using a periodic 2d mesh. An illustration of the padding can be viewed below: \n",
    "\n",
    "<center><img src=\"images/periodicity_conversion.png\" alt=\"Drawing\" style=\"width: 1000px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # make geometry for problem\n",
    "    length = (-0.720, 0.720)\n",
    "    height  = (-0.720, 0.720)\n",
    "    box_bounds = {x: length, y: height}\n",
    "\n",
    "    # define geometry\n",
    "    rec = rect(\n",
    "        (length[0], height[0]),\n",
    "        (length[1], height[1])\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling and Nondimensionalizing the Problem\n",
    "\n",
    "The input geometry of the problem can be scaled such that the characteristic length is closer to unity and the geometry is centered around origin. Also, it is often advantageous to work with the nondimensionalized form of physical quantities and PDEs. This can be achieved by output scaling, or nondimensionalizing the PDEs itself using some characteristic dimensions and properties. Simple tricks like these can help improve the convergence behavior and can also give more accurate results.\n",
    "\n",
    "Below we now take the real world parameters that we have and nondimensalise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # Scaling and Nondimensionalizing the Problem\n",
    "    \n",
    "    #############\n",
    "    # Real Params\n",
    "    #############\n",
    "    fluid_kinematic_viscosity = 1.655e-5  # m**2/s \n",
    "    fluid_density = 1.1614  # kg/m**3\n",
    "    fluid_specific_heat = 1005  # J/(kg K)\n",
    "    fluid_conductivity = 0.0261  # W/(m K)\n",
    "\n",
    "    ################\n",
    "    # Non dim params for normalisation \n",
    "    ################\n",
    "    # Diameter of Earth : 12742000 m over range of 1.440\n",
    "    length_scale = 12742000/1.440 \n",
    "    # 60 hrs = 1 timestep- every inference frame (0.1) is a 6 hour prediction (s)\n",
    "    time_scale = 60*60*60 \n",
    "    # Calcuale velocity & pressure scale \n",
    "    velocity_scale = length_scale / time_scale  # m/s\n",
    "    pressure_scale = fluid_density * ((length_scale / time_scale) ** 2)  # kg / (m s**2)\n",
    "    # Density scale\n",
    "    density_scale = 1.1614  # kg/m3\n",
    "\n",
    "\n",
    "    ##############################\n",
    "    # Nondimensionalization Params for NavierStokes fn\n",
    "    ##############################\n",
    "    # fluid params\n",
    "    nd_fluid_kinematic_viscosity = fluid_kinematic_viscosity / ( length_scale ** 2 / time_scale)\n",
    "    nd_fluid_density = fluid_density / density_scale\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use these parameters to scale our velocity and pressure values to train our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Defining the PDEs and creating the nodes.\n",
    "\n",
    "Navier Stokes Equation is available as part of the Modulus PDE Toolbox. Let's start the initialization of the equation. Since we are approximating to predict the flow, we will be setting it to a 2-dimensional solver that is time-dependent. We will then use the nondimensionalized parameters from the values calculated above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# make navier stokes equations\n",
    "ns = NavierStokes(nu=nd_fluid_kinematic_viscosity, rho=nd_fluid_density, dim=2, time=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Neural Network nodes\n",
    "\n",
    "The default `FullyConnectedArch` represents a 6 layer MLP (multi-layer perceptron) architecture with each layer containing 512 nodes and uses swish as the activation function, we will be using a layer size of 256 for our case.\n",
    "\n",
    "We will define all the code for the problem in the `run` function as shown below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "@modulus.sym.main(config_path=\"conf\", config_name=\"config\")\n",
    "def run(cfg: ModulusConfig) -> None:\n",
    "\n",
    "    # make network \n",
    "    flow_net = FullyConnectedArch(\n",
    "        input_keys=[Key(\"x\"), Key(\"y\"), Key(\"t\")],\n",
    "        output_keys=[Key(\"u\"), Key(\"v\"), Key(\"p\")],\n",
    "        periodicity={\"x\": length, \"y\" : height}, \n",
    "        layer_size=256,\n",
    "    )\n",
    "\n",
    "    # make nodes to unroll graph on\n",
    "    nodes = ns.make_nodes() + [flow_net.make_node(name=\"flow_net\")]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A small note on periodicity: \n",
    "\n",
    "As we discussed earlier, since our aim is the predict the flow from a 2d projected input mesh, we can define the periodicity to repeat itself and modify the initial conditions so that the Boundary Constraints need not be enforced, this would set a periodic boundary for the range $(-0.720 , 719)$, this has been set above using the `periodicity` parameter. \n",
    "\n",
    "```python\n",
    "periodicity={\"x\": length, \"y\" : height}, \n",
    "```\n",
    "\n",
    "Similarly, we can modify the input initial conditions to allow us to periodically repeat it, this can be done by taking our input image $(720,1440)$ and fill the mesh to create a 2d tile of the dimension $(1440,1440)$ \n",
    "\n",
    "<center><img src=\"images/periodicity_conversion.png\" alt=\"Drawing\" style=\"width: 1200px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Setting up the Domain: Assigning the boundary and PDE constraints\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # make domain add constraints to the solver\n",
    "    domain = Domain()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An L2 loss (default and can be modified) is then constructed from these constraints, which is used by the optimizer to minimize on. Specifying the constraints in this fashion is called soft-constraints.  \n",
    "\n",
    "$$L = L_{BC} + L_{Residual}$$\n",
    "\n",
    "**Initial constraints:**\n",
    "\n",
    "The initial conditions can be sampled using `PointwiseConstraint.from_numpy()` method. This will sample the points for the training given using the `invar` and `outvar` dictionaries provided, going forward we will also read the initial conditions from a `numpy` file, apply the scale transformations and use it for training our model.\n",
    "\n",
    "The number of points to sample on each constraint is specified using the `batch_size` parameter. \n",
    "\n",
    "**Equations to solve:** The Navier-Stokes PDE we defined is enforced on all the points in the interior region. We will use `PointwiseInteriorConstraint` class to sample points in the interior of the geometry. For this problem we have set the `\"continuity\": 0` ,  `\"momentum_x\": 0` and  `\"momentum_y\": 0` for the mesh. The parameter `bounds`, determines the range for sampling the values for variables $x$ and $y$. We will also define a function to load values from numpy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def read_wf_data(velocity_scale,pressure_scale):\n",
    "    path = \"/workspace/python/source_code/navier_stokes/data_lat.npy\"\n",
    "    print(path)\n",
    "    ic = np.load(path).astype(np.float32)\n",
    "    \n",
    "    Pa_to_kgm3 = 0.10197\n",
    "    mesh_y, mesh_x = np.meshgrid(\n",
    "        np.linspace(-0.720, 0.719, ic[0].shape[0]),\n",
    "        np.linspace(-0.720, 0.719, ic[0].shape[1]),\n",
    "        indexing=\"ij\",\n",
    "    )\n",
    "    invar = {}\n",
    "    invar[\"x\"] = np.expand_dims(mesh_x.astype(np.float32).flatten(),axis=-1)\n",
    "    invar[\"y\"] = np.expand_dims(mesh_y.astype(np.float32).flatten(),axis=-1)\n",
    "    invar[\"t\"] = np.full_like(invar[\"x\"], 0)\n",
    "    outvar = {}\n",
    "    outvar[\"u\"] = np.expand_dims((ic[0]/velocity_scale).flatten(),axis=-1)\n",
    "    outvar[\"v\"] = np.expand_dims((ic[1]/velocity_scale).flatten(),axis=-1)\n",
    "    outvar[\"p\"] = np.expand_dims((ic[2]*Pa_to_kgm3/pressure_scale).flatten(),axis=-1)\n",
    "    \n",
    "    return invar, outvar\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now pass the `velocity` and `pressure` scale values obtained from above to scale our inputs and get the `invar` and `outvar` dictionaries for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # make initial condition \n",
    "    ic_invar,ic_outvar = read_wf_data(velocity_scale,pressure_scale)\n",
    "    \n",
    "    ic = PointwiseConstraint.from_numpy(\n",
    "            nodes,\n",
    "            ic_invar,\n",
    "            ic_outvar,\n",
    "            batch_size=cfg.batch_size.initial_condition,\n",
    "            lambda_weighting=lambda_weighting,\n",
    "        )\n",
    "    navier.add_constraint(ic, name=\"ic\")\n",
    "    \n",
    "    # make interior constraint\n",
    "    interior = PointwiseInteriorConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=rec,\n",
    "        outvar={\"continuity\": 0, \"momentum_x\": 0, \"momentum_y\": 0},\n",
    "        bounds=box_bounds,\n",
    "        batch_size=cfg.batch_size.interior,\n",
    "        parameterization=time_range,\n",
    "    )\n",
    "    navier.add_constraint(interior, name=\"interior\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Adding Inferencer data\n",
    "\n",
    "For visualising the Inferred output from the model, we use the `PointVTKInference` class to run inference on our system and save the output to a file for visualising, let us now add it to the domain. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # add inference data for time slices\n",
    "    for i, specific_time in enumerate(np.linspace(0, time_window_size, 10)):\n",
    "        vtk_obj = VTKUniformGrid(\n",
    "            bounds=[(-0.720, 0.720), (-0.360, 0.360)],\n",
    "            npoints=[1440,720],\n",
    "            export_map={\"u\": [\"u\", \"v\"], \"p\": [\"p\"]},\n",
    "        )\n",
    "        grid_inference = PointVTKInferencer(\n",
    "            vtk_obj=vtk_obj,\n",
    "            nodes=nodes,\n",
    "            input_vtk_map={\"x\": \"x\", \"y\": \"y\"},\n",
    "            output_names=[\"u\", \"v\", \"p\"],\n",
    "            requires_grad=False,\n",
    "            invar={\"t\": np.full([720 *1440, 1], specific_time)},\n",
    "            batch_size=100000,\n",
    "        )\n",
    "        navier.add_inferencer(grid_inference, name=\"time_slice_\" + str(i).zfill(4))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Hydra configuration\n",
    "\n",
    "More information on the available configurations can be found in [Modulus Configuration](https://docs.nvidia.com/deeplearning/modulus/modulus-sym/user_guide/features/configuration.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "defaults :\n",
    "  - modulus_default\n",
    "  - arch:\n",
    "      - fully_connected\n",
    "  - scheduler: tf_exponential_lr\n",
    "  - optimizer: adam\n",
    "  - loss: sum\n",
    "  - _self_\n",
    "\n",
    "save_filetypes : \"vtk,npz\"\n",
    "\n",
    "scheduler:\n",
    "  decay_rate: 0.95\n",
    "  decay_steps: 3000\n",
    "\n",
    "training:\n",
    "  rec_results_freq : 1000\n",
    "  rec_constraint_freq: 5000\n",
    "  max_steps : 125000\n",
    "\n",
    "batch_size:\n",
    "  initial_condition: 2048\n",
    "  interior: 2048\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Putting everything together: Solver and training\n",
    "\n",
    " The solver can then be executed using the `solve` method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # make solver\n",
    "    slv = Solver(cfg, domain)\n",
    "\n",
    "    # start solver\n",
    "    slv.solve()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to solve the Problem statement !\n",
    "\n",
    "This example is already saved for you and the code block below executes that script [`navier_stokes.py`](../../source_code/navier_stokes/navier_stokes.py). You are encouraged to open the script and go through the code once before executing. Also, feel free to edit the parameters in the [`config.yaml`](../../source_code/navier_stokes/conf/config.yaml) file of the model and see its effect on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Given the time and bootcamp constraints in this scenario, we are leveraging a pre-trained approach to optimize our model development process. This allows us to utilize an existing model that has been trained on the dataset earlier, thereby reducing the time and resources needed to train the model from scratch. By adopting this approach, we aim to improve the efficiency and speed of our model development while ensuring that our performance metrics meet the desired criteria. Let us train for 5000 steps, which will take around 5-10 minutes on a A100*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"RANK\"]=\"0\"\n",
    "os.environ[\"WORLD_SIZE\"]=\"1\"\n",
    "os.environ[\"MASTER_ADDR\"]=\"localhost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ../../source_code/navier_stokes/navier_stokes.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the solution\n",
    "\n",
    "Now let's plot the prediction for the following timesteps obtained from neural network solution. A sample script to plot the results is shown below. If the training is complete, you should get the results like shown below. \n",
    "\n",
    "<img src=\"images/u_plot.png\" alt=\"Drawing\"/>\n",
    "\n",
    "\n",
    "**Kindly note:**  Several assumptions were made in this particular problem statement. while the prediction model provides us with results, this is not a real-world representation due to the constraints of the bootcamp environment, but the problem statement was defined in such a way that we employ these approximations to help get the user get comfortable with Modulus without getting into the complexities of all the equations needed to design a Numerical weather prediction system. We will be looking at a much realistic weather prediction approach in the Data-driven approach using the FourCastNet model in one of the upcoming notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.matplotlib_fname()\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "network_dir = \"./outputs/navier_stokes/inferencers/time_slice_000\"\n",
    "\n",
    "i=0\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(15,10))\n",
    "\n",
    "for row in ax:\n",
    "    for col in row:\n",
    "        data = np.load(network_dir + str(i) +\".npz\", allow_pickle=True)\n",
    "        data = np.atleast_1d(data.f.arr_0)[0]\n",
    "        x,y,u,v,p = data['x'] , data['y'] , data['u'] , data['v'] , data['p']\n",
    "        u_r = np.reshape(u, (720, 1440))\n",
    "        v_r = np.reshape(v, (720, 1440))\n",
    "        p_r = np.reshape(p, (720, 1440))\n",
    "        i = i+1\n",
    "        tmp = col.imshow(u_r,cmap=cm.coolwarm) # Feel free to change from u_r to v_r or p_r to visualise the following parameters\n",
    "\n",
    "        col.set_title(\"Time step : \"+ str(i))\n",
    "\n",
    "fig.subplots_adjust(right=0.9)\n",
    "cbar_ax = fig.add_axes([0.95, 0.15, 0.03, 0.7])\n",
    "fig.colorbar(tmp, cax=cbar_ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising with ParaView\n",
    "\n",
    "Let us now visualise the above generated outputs with ParaView. \n",
    "\n",
    "Let us now select the files of respective Timesteps as follows: \n",
    "\n",
    "Step 1: Head to `jupyter_notebook/navier_stokes/outputs/navier_stokes/inferencers/` to download the respective `.vti` files for visualisation.\n",
    "\n",
    "<img src=\"images/paraview_file.png\" alt=\"Drawing\"/>\n",
    "\n",
    "Step 2: Import them into Paraview and use the loop option to loop throgh the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(\"images/paraview.webm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In the context of our discussion on Physics Informed approaches in Modulus, we have reviewed several examples that highlight the significance and potential benefits of incorporating physical principles and constraints in Neural networks.\n",
    "\n",
    "Furthermore, we would like to inform you that we have provided an optional notebook that addresses the Data assimilation problem discussed in the introduction notebook. This additional resource will further expand on the concepts and techniques involved in assimilating data into physical models and demonstrate how this approach can enhance the accuracy and predictive power of the model. We encourage you to review this optional notebook, as it can provide valuable insights into the practical implementation of Physics Informed approaches in various fields, including engineering, physics, and data science. \n",
    "\n",
    "However, we will now shift our focus to data-driven approaches. We will delve into hands-on examples to illustrate how the six-step approach can be used to solve problems using the data-driven approach, which help us to analyze and extract insights from large and complex datasets. By following this approach, we can identify patterns and trends within the data that may not be immediately evident and use this information to develop predictive models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Industrial use-case of Modulus\n",
    "\n",
    "While we intend to cover Modulus at an introductory level, focusing on key concepts using sample examples, Modulus is capable of doing much more, and the applications below showcase its larger potential across various industries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1920\"\n",
       "            height=\"1200\"\n",
       "            src=\"../industry_modulus.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7991369416c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"../industry_modulus.pdf\", width=1920, height=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "Don't forget to check out additional [Open Hackathons Resources](https://www.openhackathons.org/s/technical-resources) and join our [OpenACC and Hackathons Slack Channel](https://www.openacc.org/community#slack) to share your experience and get more help from the community.\n",
    "\n",
    "---\n",
    "\n",
    "# Licensing\n",
    "\n",
    "Copyright Â© 2023 OpenACC-Standard.org.  This material is released by OpenACC-Standard.org, in collaboration with NVIDIA Corporation, under the Creative Commons Attribution 4.0 International (CC BY 4.0). These materials may include references to hardware and software developed by other entities; all applicable licensing and copyrights apply."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
