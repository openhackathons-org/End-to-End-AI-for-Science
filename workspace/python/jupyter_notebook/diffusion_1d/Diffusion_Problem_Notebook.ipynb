{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steady State Diffusion in a Composite Bar using PINNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will solve the steady state 1-dimensional heat transfer in a composite bar and also use a Parameterized approach for the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contents of the Notebook\n",
    "- [Steady State 1D Diffusion in a Composite Bar using PINNs](#Steady-State-1D-Diffusion-in-a-Composite-Bar-using-PINNs)\n",
    "    - [Problem Description](#Problem-Description)\n",
    "    - [Case Setup](#Case-Setup)\n",
    "    - [Step 1: Creating the geometry](#Step-1:-Creating-the-geometry)\n",
    "    - [Step 2: Defining the PDEs and creating the nodes](#Step-2:-Defining-the-PDEs-and-creating-the-nodes)\n",
    "    - [Step 3: Setting up the domain and assigning the boundary and PDE constraints](#Step-3:-Setting-up-the-domain-and-assigning-the-boundary-and-PDE-constraints)\n",
    "    - [Step 4: Adding Validators, Inferencers and Monitors](#Step-4:-Adding-Validators,-Inferencers-and-Monitors)\n",
    "    - [Step 5: Hydra configuration](#Step-5:-Hydra-configuration)\n",
    "    - [Step 6: Putting everything together: Solver and training](#Step-6:-Putting-everything-together:-Solver-and-training)\n",
    "    - [Visualizing the solution](#Visualizing-the-solution)\n",
    "- [Parameterized 1D Diffusion of Composite Bar](#Parameterized-1D-Diffusion-of-Composite-Bar)\n",
    "    - [Case Setup - Parameterized](#Case-Setup---Parameterized)\n",
    "    - [Step 1: Creating the geometry - Parameterized](#Step-1:-Creating-the-geometry---Parameterized)\n",
    "    - [Step 2: Adding Parameterized PDE and Neural Network nodes](#Step-2:-Adding-Parameterized-PDE-and-Neural-Network-nodes)\n",
    "    - [Step 3: Adding Parameterized boundary and PDE Constraints](#Step-3:-Adding-Parameterized-boundary-and-PDE-Constraints)\n",
    "    - [Step 4: Adding Validators and Monitors](#Step-4:-Adding-Validators-and-Monitors)\n",
    "    - [Step 5: Hydra configuration - Parameterized](#Step-5:-Hydra-configuration---Parameterized)\n",
    "    - [Step 6: Solver and Training](#Step-6:-Solver-and-Training)\n",
    "    - [Visualizing the solution - Parameterized](#Visualizing-the-solution---Parameterized)\n",
    "    \n",
    "\n",
    "#### Learning Outcomes\n",
    "- How to use the Constructive Solid Geometry (CSG) module\n",
    "- How to use Modulus to solve a parameterized PDEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steady State 1D Diffusion in a Composite Bar using PINNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Description\n",
    "\n",
    "Our aim is to obtain the temperature distribution inside the bar that is made up of two materials with different thermal conductivity. The geometry and the problem specification of the problem can be seen below\n",
    "\n",
    "<center><img src=\"images/diffusion_bar_geometry.png\" alt=\"Drawing\" style=\"width: 600px;\"/></center>\n",
    "\n",
    "The composite bar extends from $x=0$ to $x=2$. The bar has material of conductivity $D_1=10$ from $x=0$ to $x=1$ and $D_2=0.1$ from $x=1$ to $x=2$. Both the ends of the bar, $x=0$ and $x=2$ are maintained at a constant temperatures of $0$ and $100$ respectively. For simplicity of modelling, we will treat the composite bar as two separate bars, bar 1 and bar 2, whose ends are joined together. We will treat the temperatures in the bar 1 as $U_1$ and the temperature in bar 2 as $U_2$. \n",
    "\n",
    "The equations and boundary conditions governing the problem can be mathematically expressed as\n",
    "\n",
    "One dimensional diffusion of temperature in bar 1 and 2:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{d}{dx}\\left( D_1\\frac{dU_1}{dx} \\right) = 0, && \\text{when } 0<x<1 \\\\\n",
    "\\frac{d}{dx}\\left( D_2\\frac{dU_2}{dx} \\right) = 0, && \\text{when } 1<x<2 \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Flux and temperature continuity at interface $(x=1)$\n",
    "$$\n",
    "\\begin{align}\n",
    "D_1\\frac{dU_1}{dx} = D_2\\frac{dU_2}{dx}, && \\text{when } x=1 \\\\\n",
    "U_1 = U_2, && \\text{when } x=1 \\\\\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Setup\n",
    "\n",
    "Now let's start the problem by importing the required libraries and packages\n",
    "\n",
    "#### Note : In this notebook we will describe the contents of the [`diffusion_bar.py`](../../source_code/diffusion_1d/diffusion_bar.py) script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import torch\n",
    "import numpy as np\n",
    "from sympy import Symbol, Eq, Function, Number\n",
    "\n",
    "import modulus\n",
    "from modulus.hydra import ModulusConfig, instantiate_arch\n",
    "from modulus.solver import Solver\n",
    "from modulus.domain import Domain\n",
    "from modulus.geometry.primitives_1d import Line1D\n",
    "from modulus.domain.constraint import (\n",
    "    PointwiseBoundaryConstraint,\n",
    "    PointwiseInteriorConstraint,\n",
    ")\n",
    "from modulus.domain.validator import PointwiseValidator\n",
    "from modulus.domain.monitor import PointwiseMonitor\n",
    "from modulus.key import Key\n",
    "from modulus.node import Node\n",
    "from modulus.eq.pde import PDE\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Creating the geometry\n",
    "\n",
    "In this problem, we will create the 1-dimensional geometry using `Line1D` class from the geometry module. The module also contains several 2d and 3d shapes like rectangle, circle, triangle, cuboids, sphere, torus, cones, tetrahedrons, etc. We will define the one dimensional line object using the two end-points. For the composite bar, we will create two separate bars as defined in the problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# params for domain\n",
    "L1 = Line1D(0,1)\n",
    "L2 = Line1D(1,2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will define the properties for the problem statement, which will later be used while making the equations, boundary conditions, etc. Also, for this problem, we can find the temperature at the interface analytically, and we will use that to form validation data to compare our neural network results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "D1 = 1e1\n",
    "D2 = 1e-1\n",
    "\n",
    "Tc = 100\n",
    "Ta = 0\n",
    "Tb = (Tc + (D1 / D2) * Ta) / (1 + (D1 / D2))\n",
    "\n",
    "print(Ta)\n",
    "print(Tb)\n",
    "print(Tc)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Defining the PDEs and creating the nodes\n",
    "\n",
    "Let's create the PDE to define the diffusion equation. We will define the equation in its most generic, transient 3-dimensional, form and then have an argument `dim` that can reduce it to lower dimensional forms. \n",
    "$$\\frac{\\partial T}{\\partial t}= \\nabla\\cdot \\left( D \\nabla T \\right) + Q$$\n",
    "\n",
    "Let's start defining the equation by inhereting from the `PDE` class. We will create the initialization method for this class that defines the equation(s) of interest. We will be defining the diffusion equation using the source(`Q`), diffusivity(`D`), symbol for diffusion(`T`). If `D` or `Q` is given as a string, we will convert it to functional form. This will allow us to solve problems with spatially/temporally varying properties. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class Diffusion(PDE):\n",
    "    name = \"Diffusion\"\n",
    "\n",
    "    def __init__(self, T=\"T\", D=\"D\", Q=0, dim=3, time=True):\n",
    "        # set params\n",
    "        self.T = T\n",
    "        self.dim = dim\n",
    "        self.time = time\n",
    "\n",
    "        # coordinates\n",
    "        x, y, z = Symbol(\"x\"), Symbol(\"y\"), Symbol(\"z\")\n",
    "\n",
    "        # time\n",
    "        t = Symbol(\"t\")\n",
    "\n",
    "        # make input variables\n",
    "        input_variables = {\"x\": x, \"y\": y, \"z\": z, \"t\": t}\n",
    "        if self.dim == 1:\n",
    "            input_variables.pop(\"y\")\n",
    "            input_variables.pop(\"z\")\n",
    "        elif self.dim == 2:\n",
    "            input_variables.pop(\"z\")\n",
    "        if not self.time:\n",
    "            input_variables.pop(\"t\")\n",
    "\n",
    "        # Temperature\n",
    "        assert type(T) == str, \"T needs to be string\"\n",
    "        T = Function(T)(*input_variables)\n",
    "\n",
    "        # Diffusivity\n",
    "        if type(D) is str:\n",
    "            D = Function(D)(*input_variables)\n",
    "        elif type(D) in [float, int]:\n",
    "            D = Number(D)\n",
    "\n",
    "        # Source\n",
    "        if type(Q) is str:\n",
    "            Q = Function(Q)(*input_variables)\n",
    "        elif type(Q) in [float, int]:\n",
    "            Q = Number(Q)\n",
    "\n",
    "        # set equations\n",
    "        self.equations = {}\n",
    "        self.equations[\"diffusion_\" + self.T] = (\n",
    "            T.diff(t)\n",
    "            - (D * T.diff(x)).diff(x)\n",
    "            - (D * T.diff(y)).diff(y)\n",
    "            - (D * T.diff(z)).diff(z)\n",
    "            - Q\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we defined the input variables $x, y, z$ and $t$ with Sympy symbols. Then we defined the functions for $T$, $D$ and $Q$ that are dependent on the input variables $(x, y, z, t)$. Using these, we can write out our simple equation $T_t = \\nabla \\cdot (D \\nabla T) + Q$. We store this equation in the class by adding it to the dictionary of `equations`.\n",
    "\n",
    "Note that we moved all the terms of the PDE either to LHS or RHS. This way, while using the equations in the constraints, we\n",
    "can assign a custom source function to the <code>’diffusion_T’</code> key instead of 0 to add more source terms to our PDE.\n",
    "Now that we have defined our PDE, you can also bundle multiple PDEs together in the same file by adding new keys to the equations dictionary. Below we show the code for the interface boundary condition where we need to maintain the field (dirichlet) and flux (neumann) continuity.\n",
    "<strong>Note:</strong> The field continuity condition is needed because we are solving for two different temperatures in the two bars. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class DiffusionInterface(PDE):\n",
    "    name = \"DiffusionInterface\"\n",
    "\n",
    "    def __init__(self, T_1, T_2, D_1, D_2, dim=3, time=True):\n",
    "        # set params\n",
    "        self.T_1 = T_1\n",
    "        self.T_2 = T_2\n",
    "        self.dim = dim\n",
    "        self.time = time\n",
    "\n",
    "        # coordinates\n",
    "        x, y, z = Symbol(\"x\"), Symbol(\"y\"), Symbol(\"z\")\n",
    "        normal_x, normal_y, normal_z = (\n",
    "            Symbol(\"normal_x\"),\n",
    "            Symbol(\"normal_y\"),\n",
    "            Symbol(\"normal_z\"),\n",
    "        )\n",
    "\n",
    "        # time\n",
    "        t = Symbol(\"t\")\n",
    "\n",
    "        # make input variables\n",
    "        input_variables = {\"x\": x, \"y\": y, \"z\": z, \"t\": t}\n",
    "        if self.dim == 1:\n",
    "            input_variables.pop(\"y\")\n",
    "            input_variables.pop(\"z\")\n",
    "        elif self.dim == 2:\n",
    "            input_variables.pop(\"z\")\n",
    "        if not self.time:\n",
    "            input_variables.pop(\"t\")\n",
    "\n",
    "        # Diffusivity\n",
    "        if type(D_1) is str:\n",
    "            D_1 = Function(D_1)(*input_variables)\n",
    "        elif type(D_1) in [float, int]:\n",
    "            D_1 = Number(D_1)\n",
    "        if type(D_2) is str:\n",
    "            D_2 = Function(D_2)(*input_variables)\n",
    "        elif type(D_2) in [float, int]:\n",
    "            D_2 = Number(D_2)\n",
    "\n",
    "        # variables to match the boundary conditions (example Temperature)\n",
    "        T_1 = Function(T_1)(*input_variables)\n",
    "        T_2 = Function(T_2)(*input_variables)\n",
    "\n",
    "        # set equations\n",
    "        self.equations = {}\n",
    "        self.equations[\"diffusion_interface_dirichlet_\" + self.T_1 + \"_\" + self.T_2] = (\n",
    "            T_1 - T_2\n",
    "        )\n",
    "        flux_1 = D_1 * (\n",
    "            normal_x * T_1.diff(x) + normal_y * T_1.diff(y) + normal_z * T_1.diff(z)\n",
    "        )\n",
    "        flux_2 = D_2 * (\n",
    "            normal_x * T_2.diff(x) + normal_y * T_2.diff(y) + normal_z * T_2.diff(z)\n",
    "        )\n",
    "        self.equations[\"diffusion_interface_neumann_\" + self.T_1 + \"_\" + self.T_2] = (\n",
    "            flux_1 - flux_2\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Neural Network nodes\n",
    "\n",
    "The default `FullyConnectedArch` represents a 6 layer MLP (multi-layer perceptron) architecture with each layer containing 512 nodes and uses swish as the activation function. We will be using a layer size of 256 for our case.\n",
    "\n",
    "We will define all the code for the problem in the `run` function as shown below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "@modulus.main(config_path=\"conf\", config_name=\"config\")\n",
    "def run(cfg: ModulusConfig) -> None:\n",
    "\n",
    "    # make list of nodes to unroll graph on\n",
    "    diff_u1 = Diffusion(T=\"u_1\", D=D1, dim=1, time=False)\n",
    "    diff_u2 = Diffusion(T=\"u_2\", D=D2, dim=1, time=False)\n",
    "    diff_in = DiffusionInterface(\"u_1\", \"u_2\", D1, D2, dim=1, time=False)\n",
    "\n",
    "    diff_net_u_1 = instantiate_arch(\n",
    "        input_keys=[Key(\"x\")],\n",
    "        output_keys=[Key(\"u_1\")],\n",
    "        cfg=cfg.arch.fully_connected,\n",
    "    )\n",
    "    diff_net_u_2 = instantiate_arch(\n",
    "        input_keys=[Key(\"x\")],\n",
    "        output_keys=[Key(\"u_2\")],\n",
    "        cfg=cfg.arch.fully_connected,\n",
    "    )\n",
    "\n",
    "    nodes = (\n",
    "        diff_u1.make_nodes()\n",
    "        + diff_u2.make_nodes()\n",
    "        + diff_in.make_nodes()\n",
    "        + [diff_net_u_1.make_node(name=\"u1_network\", jit=cfg.jit)]\n",
    "        + [diff_net_u_2.make_node(name=\"u2_network\", jit=cfg.jit)]\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Setting up the domain and assigning the boundary and PDE constraints\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # make domain add constraints to the solver\n",
    "    domain = Domain()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An L2 loss (default and can be modified) is then constructed from these constraints, which is used by the optimizer to minimize on. Specifying the constraints in this fashion is called soft-constraints.  \n",
    "\n",
    "$$L = L_{BC} + L_{Residual}$$\n",
    "\n",
    "**Boundary constraints:**\n",
    "\n",
    "The boundary can be sampled using `PointwiseBoundaryConstraint` class. This will sample the entire boundary of the geometry we specify in the `geometry` argument, in this case, both the endpoints of the 1d line. A particular boundary of the geometry can be sub-sampled by using a particular criterion using the `criteria` parameter. For example, to sample the left end of `L1`, `criteria` is set to `Eq(x, 0)`. \n",
    "\n",
    "The desired values for the boundary condition are listed as a dictionary in `outvar` argument. For this problem,  we have `'u_1':0` at $x=0$ and `'u_2':100` at $x=2$. At $x=1$, we have the interface condition `'diffusion_interface_dirichlet_u_1_u_2':0` and `'diffusion_interface_neumann_u_1_u_2':0` that we defined earlier (i.e. $U_1=U_2$ and $D_1\\frac{dU_1}{dx}=D_2\\frac{dU_2}{dx}$). These dictionaries are then used when unrolling the computational graph (specified using the `nodes` argument) for training.\n",
    "\n",
    "The number of points to sample on each boundary is specified using the `batch_size` parameter. \n",
    "\n",
    "**Equations to solve:** The Diffusion PDE we defined is enforced on all the points in the\n",
    "interior of both the bars, `L1` and `L2`. We will use `PointwiseInteriorConstraint` class to sample points in the interior of the geometry. Again, the appropriate geometry is specified in the `geometry` argument; the equations to solve are specified as a dictionary input to `outvar` argument. These dictionaries are then used when unrolling the computational graph (specified using the `nodes` argument) for training.\n",
    "\n",
    "For this problem we have the `'diffusion_u_1':0` and `'diffusion_u_2':0` for bars `L1` and `L2` respectively. The parameter `bounds`, determines the range for sampling the values for variables $x$ and $y$. The optional `lambda` parameter can be used to determine the weights for different losses. In this problem, we weight the loss on each point equally, and hence it is not used (defaults to 1) in this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # sympy variables\n",
    "    x = Symbol(\"x\")\n",
    "\n",
    "    # right hand side (x = 2) Pt c\n",
    "    rhs = PointwiseBoundaryConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=L2,\n",
    "        outvar={\"u_2\": Tc},\n",
    "        batch_size=cfg.batch_size.rhs,\n",
    "        criteria=Eq(x, 2),\n",
    "    )\n",
    "    domain.add_constraint(rhs, \"right_hand_side\")\n",
    "\n",
    "    # left hand side (x = 0) Pt a\n",
    "    lhs = PointwiseBoundaryConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=L1,\n",
    "        outvar={\"u_1\": Ta},\n",
    "        batch_size=cfg.batch_size.lhs,\n",
    "        criteria=Eq(x, 0),\n",
    "    )\n",
    "    domain.add_constraint(lhs, \"left_hand_side\")\n",
    "\n",
    "    # interface 1-2\n",
    "    interface = PointwiseBoundaryConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=L1,\n",
    "        outvar={\n",
    "            \"diffusion_interface_dirichlet_u_1_u_2\": 0,\n",
    "            \"diffusion_interface_neumann_u_1_u_2\": 0,\n",
    "        },\n",
    "        batch_size=cfg.batch_size.interface,\n",
    "        criteria=Eq(x, 1),\n",
    "    )\n",
    "    domain.add_constraint(interface, \"interface\")\n",
    "\n",
    "    # interior 1\n",
    "    interior_u1 = PointwiseInteriorConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=L1,\n",
    "        outvar={\"diffusion_u_1\": 0},\n",
    "        bounds={x: (0, 1)},\n",
    "        batch_size=cfg.batch_size.interior_u1,\n",
    "    )\n",
    "    domain.add_constraint(interior_u1, \"interior_u1\")\n",
    "\n",
    "    # interior 2\n",
    "    interior_u2 = PointwiseInteriorConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=L2,\n",
    "        outvar={\"diffusion_u_2\": 0},\n",
    "        bounds={x: (1, 2)},\n",
    "        batch_size=cfg.batch_size.interior_u2,\n",
    "    )\n",
    "    domain.add_constraint(interior_u2, \"interior_u2\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Adding Validators, Inferencers and Monitors\n",
    "\n",
    "For this 1d bar problem where the conductivity is constant in each bar, the temperature varies linearly with the position inside the solid. The analytical solution can then be given as:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "U_1 = xT_b + (1-x)T_a, && \\text{when } 0 \\leq x \\leq 1 \\\\\n",
    "U_2 = (x-1)T_c + (2-x)T_b, && \\text{when } 1 \\leq x \\leq 2 \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where, \n",
    "$$\n",
    "\\begin{align}\n",
    "T_a = U_1|_{x=0}, && T_c = U_2|_{x=2}, && \\frac{\\left(T_c + \\left( D_1/D_2 \\right)T_a \\right)}{1+ \\left( D_1/D_2 \\right)}\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Now, let's create the validators. The validation data is added to the domain using the `PointwiseValidator` class. We use numpy to solve for the `u_1` and `u_2` based on the analytical expressions we showed above. The dictionary of generated numpy arrays (`invar_numpy` and `outvar_numpy`) for input and output variables and the appropriate nodes are used in the definition of the constructor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # validation data\n",
    "    x = np.expand_dims(np.linspace(0, 1, 100), axis=-1)\n",
    "    u_1 = x * Tb + (1 - x) * Ta\n",
    "    invar_numpy = {\"x\": x}\n",
    "    outvar_numpy = {\"u_1\": u_1}\n",
    "    val = PointwiseValidator(nodes=nodes,invar=invar_numpy, true_outvar=outvar_numpy)\n",
    "    domain.add_validator(val, name=\"Val1\")\n",
    "\n",
    "    # make validation data line 2\n",
    "    x = np.expand_dims(np.linspace(1, 2, 100), axis=-1)\n",
    "    u_2 = (x - 1) * Tc + (2 - x) * Tb\n",
    "    invar_numpy = {\"x\": x}\n",
    "    outvar_numpy = {\"u_2\": u_2}\n",
    "    val = PointwiseValidator(nodes=nodes, invar=invar_numpy, true_outvar=outvar_numpy)\n",
    "    domain.add_validator(val, name=\"Val2\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Monitors \n",
    "\n",
    "Modulus library allows you to monitor desired quantities in Tensorboard as the simulation progresses and\n",
    "assess the convergence. A `PointwiseMonitor` can be used to create such a feature. Examples of such quantities can be point values of variables, surface averages, volume averages or any derived quantities that can be formed using the variables being solved.\n",
    "\n",
    "The variables are available as PyTorch tensors. We can perform tensor operations available in PyTorch to compute any desired derived quantity of our choice. \n",
    "\n",
    "In the code below, we create monitors for flux at the interface. The variable `u_1__x` represents the derivative of `u_1` in x-direction (two underscores (`__`) and the variable (`x`)). The same notation is used while handling other derivatives using the Modulus library. (eg. a neumann boundary condition of $\\frac{dU_1}{dx}=0$ can be assigned as `'u_1__x':0` in the training domain for solving the same problem with an adiabatic/fixed flux boundary condition). \n",
    "\n",
    "The points to sample can be selected in a similar way as we did for specifying some of the interior constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # make monitors\n",
    "    invar_numpy = {\"x\": [[1.0]]}\n",
    "    monitor = PointwiseMonitor(\n",
    "        invar_numpy,\n",
    "        output_names=[\"u_1__x\"],\n",
    "        metrics={\"flux_u1\": lambda var: torch.mean(var[\"u_1__x\"])},\n",
    "        nodes=nodes,\n",
    "        requires_grad=True,\n",
    "    )\n",
    "    domain.add_monitor(monitor)\n",
    "\n",
    "    monitor = PointwiseMonitor(\n",
    "        invar_numpy,\n",
    "        output_names=[\"u_2__x\"],\n",
    "        metrics={\"flux_u2\": lambda var: torch.mean(var[\"u_2__x\"])},\n",
    "        nodes=nodes,\n",
    "        requires_grad=True,\n",
    "    )\n",
    "    domain.add_monitor(monitor)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Hydra configuration\n",
    "\n",
    "More information on the available configurations can be found in [Modulus Configuration](https://docs.nvidia.com/deeplearning/modulus/text/features/configuration.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "defaults :\n",
    "  - modulus_default\n",
    "  - arch:\n",
    "      - fully_connected\n",
    "  - scheduler: tf_exponential_lr\n",
    "  - optimizer: adam\n",
    "  - loss: sum\n",
    "  - _self_\n",
    "\n",
    "arch:\n",
    "    fully_connected:\n",
    "        layer_size: 256\n",
    "\n",
    "save_filetypes : \"vtk,npz\"\n",
    "\n",
    "scheduler:\n",
    "  decay_rate: 0.95\n",
    "  decay_steps: 100\n",
    "\n",
    "optimizer: \n",
    "  lr : 1e-4\n",
    "\n",
    "training:\n",
    "  rec_results_freq: 1000\n",
    "  max_steps : 5000\n",
    "\n",
    "batch_size:\n",
    "  rhs: 2\n",
    "  lhs: 2\n",
    "  interface: 2\n",
    "  interior_u1: 200\n",
    "  interior_u2: 200\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Putting everything together: Solver and training\n",
    "\n",
    " The solver can then be executed using the `solve` method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # make solver\n",
    "    slv = Solver(cfg, domain)\n",
    "\n",
    "    # start solver\n",
    "    slv.solve()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to solve the PDEs !\n",
    "\n",
    "This example is already saved for you and the code block below executes that script [`diffusion_bar.py`](../../source_code/diffusion_1d/diffusion_bar.py). You are encouraged to open the script and go through the code once before executing. Also, feel free to edit the parameters in the [`config.yaml`](../../source_code/diffusion_1d/conf/) file of the model and see its effect on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"RANK\"]=\"0\"\n",
    "os.environ[\"WORLD_SIZE\"]=\"1\"\n",
    "os.environ[\"MASTER_ADDR\"]=\"localhost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ../../source_code/diffusion_1d/diffusion_bar.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the solution\n",
    "\n",
    "Now, let's plot the temperature along the bar for the analytical and the neural network solution. A sample script to plot the results is shown below. If the training is complete, you should get the results like shown below. As we can see, our neural network solution and the analytical solution match almost exactly for this diffusion problem. \n",
    "\n",
    "<img src=\"images/image_diffusion_problem_bootcamp.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "network_dir = \"./outputs/diffusion_bar/validators/\"\n",
    "data_1 = np.load(network_dir + \"Val1.npz\", allow_pickle=True)\n",
    "data_2 = np.load(network_dir + \"Val2.npz\", allow_pickle=True)\n",
    "data_1 = np.atleast_1d(data_1.f.arr_0)[0]\n",
    "data_2 = np.atleast_1d(data_2.f.arr_0)[0]\n",
    "\n",
    "plt.plot(data_1[\"x\"][:, 0], data_1[\"pred_u_1\"][:, 0], \"--\", label=\"u_1_pred\")\n",
    "plt.plot(data_2[\"x\"][:, 0], data_2[\"pred_u_2\"][:, 0], \"--\", label=\"u_2_pred\")\n",
    "plt.plot(data_1[\"x\"][:, 0], data_1[\"true_u_1\"][:, 0], label=\"u_1_true\")\n",
    "plt.plot(data_2[\"x\"][:, 0], data_2[\"true_u_2\"][:, 0], label=\"u_2_true\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameterized 1D Diffusion of Composite Bar\n",
    "\n",
    "As we discussed in the introductory notebook, one important advantage of a PINN solver over traditional numerical methods is its ability to solve parameterized geometries and PDEs. This was initially proposed in the [paper](https://arxiv.org/abs/1906.02382) published by Sun et al. This allows us significant computational advantage, as one can now use PINNs to solve for multiple designs/cases in a single training. Once the training is complete, it is possible to run inference on several geometry/physical parameter combinations as a post-processing step without solving the forward problem again. \n",
    "\n",
    "To demonstrate the concept, we will train the same 1d diffusion problem, but now by parameterizing the conductivity of the first bar in the range $(5, 25)$. Once the training is complete, we can obtain the results for any conductivity value in that range saving us the time to train multiple models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Setup - Parameterized\n",
    "\n",
    "The definition of equations remains the same for this part. Since earlier, while defining the equations, we already defined the constants and coefficients of the PDE to be either numerical values or strings, this will allow us to parameterize <code>D1</code> by passing it as a string while calling the equations and making the neural network. Now let's start by creating the parameterized train domain. We will skip the parts common to the previous section and only discuss the changes. The complete script can be referred in <a href=\"../../source_code/diffusion_1d/diffusion_bar_parameterized.py\" rel=\"nofollow\"><code>diffusion_bar_parameterized.py</code></a>. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Creating the geometry - Parameterized\n",
    "\n",
    "In this problem, we will create the 1-dimensional geometry using `Line1D` class from the geometry module. The module also contains several 2d and 3d shapes like rectangle, circle, triangle, cuboids, sphere, torus, cones, tetrahedrons, etc. We will define the one dimensional line object using the two end-points. For the composite bar, we will create two separate bars as defined in the problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# params for domain\n",
    "L1 = Line1D(0,1)\n",
    "L2 = Line1D(1,2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Adding Parameterized PDE and Neural Network nodes\n",
    "\n",
    "Before starting out to create the nodes and domain, we will create the symbolic variable for the $D_1$ and also specify the range of variation for the variable. While the simulation runs, we will validate it against the same diffusion coefficient that we solved earlier i.e. $D_1=10$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# params for domain\n",
    "L1 = Line1D(0, 1)\n",
    "L2 = Line1D(1, 2)\n",
    "\n",
    "D1 = Symbol(\"D1\")\n",
    "D1_range = {D1: (5, 25)}\n",
    "D1_validation = 1e1\n",
    "\n",
    "D2 = 1e-1\n",
    "\n",
    "Tc = 100\n",
    "Ta = 0\n",
    "Tb = (Tc + (D1 / D2) * Ta) / (1 + (D1 / D2))\n",
    "Tb_validation = float(Tb.evalf(subs={D1: 1e1}))\n",
    "\n",
    "print(Ta)\n",
    "print(Tb)\n",
    "print(Tc)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training the parameterized model, we will have the symbolic parameters defined as inputs to both the neural networks in `diff_net_u_1` and `diff_net_u_2` viz. `'D1'` along with the usual x coordinate. The outputs remain the same as what we would have for any other non-parameterized simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "@modulus.main(config_path=\"conf\", config_name=\"config_param\")\n",
    "def run(cfg: ModulusConfig) -> None:\n",
    "    # make list of nodes to unroll graph on\n",
    "    diff_u1 = Diffusion(T=\"u_1\", D=\"D1\", dim=1, time=False)\n",
    "    diff_u2 = Diffusion(T=\"u_2\", D=D2, dim=1, time=False)\n",
    "    diff_in = DiffusionInterface(\"u_1\", \"u_2\", \"D1\", D2, dim=1, time=False)\n",
    "\n",
    "    diff_net_u_1 = instantiate_arch(\n",
    "        input_keys=[Key(\"x\"), Key(\"D1\")],\n",
    "        output_keys=[Key(\"u_1\")],\n",
    "        cfg=cfg.arch.fully_connected,\n",
    "    )\n",
    "    diff_net_u_2 = instantiate_arch(\n",
    "        input_keys=[Key(\"x\"), Key(\"D1\")],\n",
    "        output_keys=[Key(\"u_2\")],\n",
    "        cfg=cfg.arch.fully_connected,\n",
    "    )\n",
    "\n",
    "    nodes = (\n",
    "        diff_u1.make_nodes()\n",
    "        + diff_u2.make_nodes()\n",
    "        + diff_in.make_nodes()\n",
    "        + [diff_net_u_1.make_node(name=\"u1_network\", jit=cfg.jit)]\n",
    "        + [diff_net_u_2.make_node(name=\"u2_network\", jit=cfg.jit)]\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Adding Parameterized boundary and PDE Constraints\n",
    "\n",
    "This part of the code is very similar to the non-parameterized version. The symbolic variables and the ranges that we described earlier need to be inputted to the `param_ranges` attribute of each boundary and internal constraints (`PointwiseBoundaryConstraint` and `PointwiseInteriorConstraint`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # make domain add constraints to the solver\n",
    "    domain = Domain()\n",
    "\n",
    "    # sympy variables\n",
    "    x = Symbol(\"x\")\n",
    "\n",
    "    # right hand side (x = 2) Pt c\n",
    "    rhs = PointwiseBoundaryConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=L2,\n",
    "        outvar={\"u_2\": Tc},\n",
    "        batch_size=cfg.batch_size.rhs,\n",
    "        criteria=Eq(x, 2),\n",
    "        parameterization=Parameterization(D1_range),\n",
    "    )\n",
    "    domain.add_constraint(rhs, \"right_hand_side\")\n",
    "\n",
    "    # left hand side (x = 0) Pt a\n",
    "    lhs = PointwiseBoundaryConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=L1,\n",
    "        outvar={\"u_1\": Ta},\n",
    "        batch_size=cfg.batch_size.lhs,\n",
    "        criteria=Eq(x, 0),\n",
    "        parameterization=Parameterization(D1_range),\n",
    "    )\n",
    "    domain.add_constraint(lhs, \"left_hand_side\")\n",
    "\n",
    "    # interface 1-2\n",
    "    interface = PointwiseBoundaryConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=L1,\n",
    "        outvar={\n",
    "            \"diffusion_interface_dirichlet_u_1_u_2\": 0,\n",
    "            \"diffusion_interface_neumann_u_1_u_2\": 0,\n",
    "        },\n",
    "        batch_size=cfg.batch_size.interface,\n",
    "        criteria=Eq(x, 1),\n",
    "        parameterization=Parameterization(D1_range),\n",
    "    )\n",
    "    domain.add_constraint(interface, \"interface\")\n",
    "\n",
    "    # interior 1\n",
    "    interior_u1 = PointwiseInteriorConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=L1,\n",
    "        outvar={\"diffusion_u_1\": 0},\n",
    "        bounds={x: (0, 1)},\n",
    "        batch_size=cfg.batch_size.interior_u1,\n",
    "        parameterization=Parameterization(D1_range),\n",
    "    )\n",
    "    domain.add_constraint(interior_u1, \"interior_u1\")\n",
    "\n",
    "    # interior 2\n",
    "    interior_u2 = PointwiseInteriorConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=L2,\n",
    "        outvar={\"diffusion_u_2\": 0},\n",
    "        bounds={x: (1, 2)},\n",
    "        batch_size=cfg.batch_size.interior_u2,\n",
    "        parameterization=Parameterization(D1_range),\n",
    "    )\n",
    "    domain.add_constraint(interior_u2, \"interior_u2\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Adding Validators and Monitors \n",
    "\n",
    " Creating these domains is again similar to the previous section. For validation data, we need to create an additional key for the string <code>'D1'</code> in the <code>invar_numpy</code>. The value for this key can be in the range we specified earlier and which we would like to validate against. It is possible to create multiple validators if required, eg. different $D_1$ values. For the monitor domain, a similar <code>invar_numpy</code> is generated that has both the <code>'x'</code> and <code>'D1'</code> keys and appropriate arrays. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # validation data\n",
    "    x = np.expand_dims(np.linspace(0, 1, 100), axis=-1)\n",
    "    u_1 = x * Tb_validation + (1 - x) * Ta\n",
    "    invar_numpy = {\"x\": x}\n",
    "    invar_numpy.update({\"D1\": np.full_like(invar_numpy[\"x\"], D1_validation)})\n",
    "    outvar_numpy = {\"u_1\": u_1}\n",
    "    val = PointwiseValidator(nodes=nodes,invar=invar_numpy, true_outvar=outvar_numpy)\n",
    "    domain.add_validator(val, name=\"Val1\")\n",
    "    \n",
    "    # make validation data line 2\n",
    "    x = np.expand_dims(np.linspace(1, 2, 100), axis=-1)\n",
    "    u_2 = (x - 1) * Tc + (2 - x) * Tb_validation\n",
    "    invar_numpy = {\"x\": x}\n",
    "    invar_numpy.update({\"D1\": np.full_like(invar_numpy[\"x\"], D1_validation)})\n",
    "    outvar_numpy = {\"u_2\": u_2}\n",
    "    val = PointwiseValidator(nodes=nodes, invar=invar_numpy, true_outvar=outvar_numpy)\n",
    "    domain.add_validator(val, name=\"Val2\")\n",
    "    \n",
    "    # make monitors\n",
    "    invar_numpy = {\"x\": [[1.0]], \"D1\": [[D1_validation]]}\n",
    "    monitor = PointwiseMonitor(\n",
    "        invar_numpy,\n",
    "        output_names=[\"u_1__x\"],\n",
    "        metrics={\"flux_u1\": lambda var: torch.mean(var[\"u_1__x\"])},\n",
    "        nodes=nodes,\n",
    "        requires_grad=True,\n",
    "    )\n",
    "    domain.add_monitor(monitor)\n",
    "\n",
    "    monitor = PointwiseMonitor(\n",
    "        invar_numpy,\n",
    "        output_names=[\"u_2__x\"],\n",
    "        metrics={\"flux_u2\": lambda var: torch.mean(var[\"u_2__x\"])},\n",
    "        nodes=nodes,\n",
    "        requires_grad=True,\n",
    "    )\n",
    "    domain.add_monitor(monitor)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Hydra configuration - Parameterized\n",
    "\n",
    "More information on the available configurations can be found in [Modulus Configuration](https://docs.nvidia.com/deeplearning/modulus/text/features/configuration.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "defaults :\n",
    "  - modulus_default\n",
    "  - arch:\n",
    "      - fully_connected\n",
    "  - scheduler: tf_exponential_lr\n",
    "  - optimizer: adam\n",
    "  - loss: sum\n",
    "  - _self_\n",
    "\n",
    "arch:\n",
    "    fully_connected:\n",
    "        layer_size: 256\n",
    "\n",
    "save_filetypes : \"vtk,npz\"\n",
    "\n",
    "scheduler:\n",
    "  decay_rate: 0.95\n",
    "  decay_steps: 200\n",
    "\n",
    "optimizer: \n",
    "  lr : 1e-4\n",
    "\n",
    "training:\n",
    "  rec_results_freq: 1000\n",
    "  max_steps : 10000\n",
    "\n",
    "batch_size:\n",
    "  rhs: 10\n",
    "  lhs: 10\n",
    "  interface: 10\n",
    "  interior_u1: 400\n",
    "  interior_u2: 400\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Solver and Training\n",
    "\n",
    "Now that we have the definitions for the various constraints and domains complete, we can form the solver and run the problem similarly to before. The code to do the same can be found below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # make solver\n",
    "    slv = Solver(cfg, domain)\n",
    "\n",
    "    # start solver\n",
    "    slv.solve()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ../../source_code/diffusion_1d/diffusion_bar_parameterized.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the solution - Parameterized\n",
    "\n",
    "The <code>.npz</code> arrays can be plotted similarly to the previous section to visualize the simulation output. You can see that we get the same answer as the analytical solution. You can try to run the problem in <code>eval</code> mode by changing the validation data and see how it performs for the other <code>D1</code> values as well. To run the model in evaluation mode (i.e. without training), you just need to <a href=\"https://docs.nvidia.com/deeplearning/modulus/text/features/configuration.html#run-modes\" rel=\"nofollow\">modify the config file</a>.  \n",
    "<img src=\"images/image_diffusion_problem_bootcamp_parameterized.png\" alt=\"Drawing\" style=\"width:500px\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "network_dir = \"./outputs/diffusion_bar_parameterized/validators/\"\n",
    "data_1 = np.load(network_dir + \"Val1.npz\", allow_pickle=True)\n",
    "data_2 = np.load(network_dir + \"Val2.npz\", allow_pickle=True)\n",
    "data_1 = np.atleast_1d(data_1.f.arr_0)[0]\n",
    "data_2 = np.atleast_1d(data_2.f.arr_0)[0]\n",
    "\n",
    "plt.plot(data_1[\"x\"][:, 0], data_1[\"pred_u_1\"][:, 0], \"--\", label=\"u_1_pred\")\n",
    "plt.plot(data_2[\"x\"][:, 0], data_2[\"pred_u_2\"][:, 0], \"--\", label=\"u_2_pred\")\n",
    "plt.plot(data_1[\"x\"][:, 0], data_1[\"true_u_1\"][:, 0], label=\"u_1_true\")\n",
    "plt.plot(data_2[\"x\"][:, 0], data_2[\"true_u_2\"][:, 0], label=\"u_2_true\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that at a fractional increase in computational time, we solved the PDE for $D_1$ ranging from (5, 25). This concept can easily be extended to more complicated problems, and this ability to solve parameterized problems comes very handy during design optimization and exploring the design space. For more examples of solving parameterized problems, please refer to <a href=\"https://docs.nvidia.com/deeplearning/modulus/index.html\" rel=\"nofollow\">Modulus User Documentation</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "Don't forget to check out additional [Open Hackathons Resources](https://www.openhackathons.org/s/technical-resources) and join our [OpenACC and Hackathons Slack Channel](https://www.openacc.org/community#slack) to share your experience and get more help from the community.\n",
    "\n",
    "---\n",
    "\n",
    "# Licensing\n",
    "\n",
    "Copyright © 2023 OpenACC-Standard.org.  This material is released by OpenACC-Standard.org, in collaboration with NVIDIA Corporation, under the Creative Commons Attribution 4.0 International (CC BY 4.0). These materials may include references to hardware and software developed by other entities; all applicable licensing and copyrights apply.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
