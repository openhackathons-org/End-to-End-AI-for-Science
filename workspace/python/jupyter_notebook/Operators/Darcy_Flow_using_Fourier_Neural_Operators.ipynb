{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ec75822",
   "metadata": {},
   "source": [
    "# Solving the Darcy-Flow problem using FNO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c8ce72",
   "metadata": {},
   "source": [
    "In this notebook, we will introduce the brief theory behind the Fourier Neural Operators and use them to solve a data-driven Darcy flow problem. The example is adapted from the [paper](https://arxiv.org/pdf/2010.08895.pdf) by Zongyi Li et al. You can also refer to the FNO example and theory from [PhysicsNeMo User Documentation](https://docs.nvidia.com/deeplearning/physicsnemo/physicsnemo-sym/user_guide/neural_operators/darcy_fno.html) for additional details. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53640294",
   "metadata": {},
   "source": [
    "#### Contents of the Notebook\n",
    "\n",
    "- [Introduction to Data-driven approach](#Introduction-to-Data-driven-approach)\n",
    "- [Theory of the Fourier Neural Operator](#Theory-of-the-Fourier-Neural-Operator)\n",
    "- [Solving the Darcy-Flow problem](#Solving-the-Darcy-Flow-problem)\n",
    "    - [Problem Description](#Problem-Description)\n",
    "    - [Case Setup](#Case-Setup)\n",
    "    - [Step 1: Loading the Data](#Step-1:-Loading-the-Data)\n",
    "    - [Step 2: Creating the nodes](#Step-2:-Creating-the-nodes)\n",
    "    - [Step 3: Creating the Domain, defining the Constraints and Validators](#Step-3:-Creating-the-Domain,-defining-the-Constraints-and-Validators)\n",
    "    - [Step 4: Adding the Validator](#Step-4:-Adding-the-Validator)\n",
    "    - [Step 5: Hydra configuration](#Step-5:-Hydra-configuration)\n",
    "    - [Step 6: Solver and Training the Model](#Step-6:-Solver-and-Training-the-Model)\n",
    "    - [Visualizing the solution](#Visualizing-the-solution)\n",
    "\n",
    "#### Learning Outcomes\n",
    "- How to use PhysicsNeMo for setting up data-driven problem using Fourier Neural Operator (FNO)\n",
    "- How to load grid data and setup data-driven constraints\n",
    "- How to use eager and lazy data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7750e256",
   "metadata": {},
   "source": [
    "## Introduction to Data-driven approach\n",
    "\n",
    "Let us revisit the following diagram from the introduction notebook. \n",
    "\n",
    "<center><img src=\"images/modulus.webp\" alt=\"Drawing\" style=\"center\"/></center>\n",
    "\n",
    "This diagram below represents the wide range of capabilities that are possessed by Neural networks and while we have explored the Physics Informed approach and Data assimilation approach of them, let us now give a short introduction to the data-driven approach. The data-driven approach involves using large datasets to train models and make predictions or decisions. These large datasets help neural networks learn the features present in unstructured data (images,text etc..); however, it is important to ensure that the data being used is representative of the problem being solved and that the model is evaluated thoroughly to avoid overfitting and other issues.\n",
    "\n",
    "We will be using the same six-step approach introduced to us earlier for the Data-driven approach, they are as follows:\n",
    "\n",
    "- **Step 1** : *Geometry and Data*\n",
    "       \n",
    "- **Step 2** : *Defining the PDEs and/or creating the nodes*\n",
    "        \n",
    "- **Step 3** : *Defining the Constraints* \n",
    "   \n",
    "- **Step 4** : *Creating a domain and adding Constraints, Inferencers, Validators, and Monitors*\n",
    "    \n",
    "- **Step 5** : *Setting up the Hydra configuration file*\n",
    "    \n",
    "- **Step 6** : *Instantiating the Solver and training the network* \n",
    "\n",
    "\n",
    "With a quick introduction to the Data-driven approach and reviewing the six-step approach, let us proceed forward solving Data-driven problems in PhysicsNeMo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1fdb0b",
   "metadata": {},
   "source": [
    "## Theory of the Fourier Neural Operator\n",
    "\n",
    "Fourier neural operator (FNO) is a data-driven architecture which can be used to parameterize solutions for a distribution of PDE solutions. The key feature of FNO is the spectral convolutions: operations that place the integral kernel in Fourier space. The spectral convolution (Fourier integral operator) is defined as follows:\n",
    "\\begin{equation}\n",
    "(\\mathcal{K}(\\mathbf{w})\\phi)(x) = \\mathcal{F}^{-1}(R_{\\mathbf{W}}\\cdot \\left(\\mathcal{F}\\right)\\phi)(x), \\quad \\forall x \\in D\n",
    "\\end{equation}\n",
    "where $\\mathcal{F}$ and $\\mathcal{F}^{-1}$ are the forward and inverse Fourier transforms, respectively.\n",
    "$R_{\\mathbf{w}}$ is the transformation which contains the learnable parameters $\\mathbf{w}$. Note this operator is calculated\n",
    "over the entire <em>structured Euclidean</em> domain $D$ discretized with $n$ points.\n",
    "Fast Fourier Transform (FFT) is used to perform the Fourier transforms efficiently, and the resulting transformation $R_{\\mathbf{w}}$ is just a finite size matrix of learnable weights. In side the spectral convolution, the Fourier coefficients are truncated to only the lower modes which intern allows explicit control over the dimensionality of the spectral space and linear operator.\n",
    "The FNO model is the composition of a fully-connected \"lifting\" layer, $L$ spectral convolutions with point-wise linear skip connections and a decoding point-wise fully-connected neural network at the end.\n",
    "\\begin{equation}\n",
    "u_{net}(\\Phi;\\theta) = \\mathcal{Q}\\circ \\sigma(W_{L} + \\mathcal{K}_{L}) \\circ ... \\circ \\sigma(W_{1} + \\mathcal{K}_{1})\\circ \\mathcal{P}(\\Phi), \\quad \\Phi=\\left\\{\\phi(x); \\forall x \\in D\\right\\}\n",
    "\\end{equation}\n",
    "in which $\\sigma(W_{i} + \\mathcal{K}_{i})$ is the spectral convolution layer $i$ with the point-wise linear transform $W_{i}$ and activation function $\\sigma(\\cdot)$. $\\mathcal{P}$ is the point-wise lifting network that projects the input into a higher-dimensional latent space, $\\mathcal{P}: \\mathbb{R}^{d_in} \\rightarrow \\mathbb{R}^{k}$.\n",
    "Similarly $\\mathcal{Q}$ is the point-wise fully-connected decoding network, $\\mathcal{P}: \\mathbb{R}^{k} \\rightarrow \\mathbb{R}^{d_out}$. Since all fully-connected components of FNO are point-wise operations, the model is invariant to the dimensionality of the input.\n",
    "\n",
    "<strong>Note:</strong> While FNO is technically invariant to the dimensionality of the discretized domain $D$, this domain <em>must</em> be a structured grid in Euclidean space. The inputs to FNO are analogous to images, but the model is invariant to the image resolution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a215738",
   "metadata": {},
   "source": [
    "## Solving the Darcy-Flow problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb61b8fd",
   "metadata": {},
   "source": [
    "### Problem Description \n",
    "We will demonstrate the use of Fourier Neural Operators on a 2D Darcy flow problem. The Darcy PDE is a second-order, elliptic PDE with the following form:\n",
    "\n",
    "\\begin{equation}\n",
    "-\\nabla \\cdot \\left(k(\\textbf{x})\\nabla u(\\textbf{x})\\right) = f(\\textbf{x}), \\quad \\textbf{x} \\in D,\n",
    "\\end{equation}\n",
    "in which $u(\\textbf{x})$ is the flow pressure, $k(\\textbf{x})$ is the permeability field and $f(\\cdot)$ is the\n",
    "forcing function. The Darcy flow can parameterize a variety of systems, including flow through porous media, elastic materials \n",
    "and heat conduction. Here you will define the domain as a 2D unit square  $D=\\left\\{x,y \\in (0,1)\\right\\}$ with the boundary condition $u(\\textbf{x})=0, \\textbf{x}\\in\\partial D$. Recall that FNO requires a structured Euclidean input such that $D = \\textbf{x}_{i}$ where $i \\in \\mathbb{N}_{N\\times N}$. Thus both the permeability and flow fields are discretized into a 2D matrix $\\textbf{K}, \\textbf{U} \\in \\mathbb{R}^{N \\times N}$.\n",
    "This problem develops a surrogate model that learns the mapping between a permeability field and the pressure field,\n",
    "$\\textbf{K} \\rightarrow \\textbf{U}$, for a distribution of permeability fields $\\textbf{K} \\sim p(\\textbf{K})$.\n",
    "This is a key distinction of this problem from other PINN examples, you are <em>not</em> learning just a single solution but rather a distribution.\n",
    "<center><img src=\"images/fno_darcy.png\" alt=\"Drawing\" style=\"width:900px\" /></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6867af1b",
   "metadata": {},
   "source": [
    "The example covered in this notebook is a data-driven problem. This means that before starting any coding, we need to make sure that we have both the training and the validation data. The training and validation datasets for this example can be found on the [Fourier Neural Operator Github page](https://github.com/zongyi-li/fourier_neural_operator). The script [`utilities.py`](../../source_code/darcy/utilities.py) is an automated script for downloading and converting this dataset.\n",
    "\n",
    "<strong>Note:</strong> In this notebook, we will walk through the contents of the <a href=\"../../source_code/darcy/darcy_FNO_lazy.py\" rel=\"nofollow\"><code>darcy_FNO_lazy.py</code></a> script.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ecee88",
   "metadata": {},
   "source": [
    "### Case Setup \n",
    "\n",
    "Now, let's start with importing the required packages and modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9507369",
   "metadata": {},
   "source": [
    "```python\n",
    "import physicsnemo\n",
    "from physicsnemo.sym.hydra import to_absolute_path, instantiate_arch, PhysicsNeMoConfig\n",
    "from physicsnemo.sym.key import Key\n",
    "\n",
    "from physicsnemo.sym.solver import Solver\n",
    "from physicsnemo.sym.domain import Domain\n",
    "from physicsnemo.sym.domain.constraint import SupervisedGridConstraint\n",
    "from physicsnemo.sym.domain.validator import GridValidator\n",
    "from physicsnemo.sym.dataset import HDF5GridDataset\n",
    "\n",
    "from physicsnemo.sym.utils.io.plotter import GridValidatorPlotter\n",
    "\n",
    "from utilities import download_FNO_dataset\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a3b2f7",
   "metadata": {},
   "source": [
    "### Step 1: Loading the Data\n",
    "\n",
    "For this data-driven problem, the first step is to get the training data into PhysicsNeMo. Before loading data, we can set any normalization value that we want to apply to the data. For this dataset, we calculated the scale and shift parameters for both the input permeability field and output pressure. Then, we set this normalization inside PhysicsNeMo by providing the scale/shift to each key, <code>Key(name, scale=(shift, scale))</code>. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c19d20",
   "metadata": {},
   "source": [
    "```python\n",
    "@physicsnemo.sym.main(config_path=\"conf\", config_name=\"config_FNO\")\n",
    "def run(cfg: PhysicsNeMoConfig) -> None:\n",
    "\n",
    "    # load training/ test data\n",
    "    input_keys = [Key(\"coeff\", scale=(7.48360e00, 4.49996e00))]\n",
    "    output_keys = [Key(\"sol\", scale=(5.74634e-03, 3.88433e-03))]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce83532",
   "metadata": {},
   "source": [
    "There are two approaches for loading data: First, use eager loading, where you immediately read the entire dataset into memory at one time. Alternatively, you can use lazy loading, where the data is loaded on a per-example basis as the model needs it for training. The eager loading eliminates potential overhead from reading data from disk during training, however, this cannot scale to large datasets. Lazy loading is used in this example for the training dataset to demonstrate this utility for larger problems. This data is in HDF5 format, which is ideal for lazy loading using the *HDF5DataFile* object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b0e95e",
   "metadata": {},
   "source": [
    "```python\n",
    "    download_FNO_dataset(\"Darcy_241\", outdir=\"datasets/\")\n",
    "    train_path = to_absolute_path(\"datasets/Darcy_241/piececonst_r241_N1024_smooth1.hdf5\")\n",
    "    test_path = to_absolute_path(\"datasets/Darcy_241/piececonst_r241_N1024_smooth2.hdf5\")\n",
    "\n",
    "    # make datasets\n",
    "    train_dataset = HDF5GridDataset(train_path, invar_keys=[\"coeff\"], outvar_keys=[\"sol\"], n_examples=1000)\n",
    "    test_dataset = HDF5GridDataset(test_path, invar_keys=[\"coeff\"], outvar_keys=[\"sol\"], n_examples=100)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de49637a",
   "metadata": {},
   "source": [
    "**Note:** The key difference when setting up eager versus lazy loading is the object passed in the variable dictionaries *invar_train* and *outvar_train*. In eager loading, these dictionaries should be of the type `Dict[str: np.array]`, where each variable is a numpy array of data. Lazy loading uses dictionaries of the type `Dict[str: DataFile]`, consisting of `DataFile` objects which are classes that are used to map between the example index and the data file.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c345db3",
   "metadata": {},
   "source": [
    "### Step 2: Creating the nodes\n",
    "\n",
    "Initializing the model and domain follows the same steps as the other PINN models we saw earlier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bcbdd3",
   "metadata": {},
   "source": [
    "```python\n",
    "    # make list of nodes to unroll graph on\n",
    "    decoder_net = instantiate_arch(\n",
    "        cfg=cfg.arch.decoder,\n",
    "        output_keys=output_keys,\n",
    "    )\n",
    "    fno = instantiate_arch(\n",
    "        cfg=cfg.arch.fno,\n",
    "        input_keys=input_keys,\n",
    "        decoder_net=decoder_net,\n",
    "    )\n",
    "    nodes = [fno.make_node('fno')]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4eee83f",
   "metadata": {},
   "source": [
    "### Step 3: Creating the Domain, defining the Constraints and Validators\n",
    "\n",
    "For the physics-informed problems in PhysicsNeMo, we typically need to define geometry and constraints based on boundary conditions and governing equations. Here, the only constraint is a <code>SupervisedGridConstraint</code>, which performs standard supervised training on grid data. This constraint supports the use of multiple workers, which is particularly important when using lazy loading. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4f7400",
   "metadata": {},
   "source": [
    "```python\n",
    "    # make domain\n",
    "    domain = Domain()\n",
    "    \n",
    "    # add constraints to domain\n",
    "    supervised = SupervisedGridConstraint(\n",
    "        nodes=nodes,\n",
    "        dataset=train_dataset,\n",
    "        batch_size=cfg.batch_size.grid,\n",
    "        num_workers=4,  # number of parallel data loaders\n",
    "    )\n",
    "    domain.add_constraint(supervised, \"supervised\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a72fcf2",
   "metadata": {},
   "source": [
    "**Note:** Grid data refers to data that can be defined in a tensor like an image. Inside PhysicsNeMo, this grid of data typically represents a spatial domain and should follow the standard dimensionality of `[batch, channel, xdim, ydim, zdim]` where channel is the dimensionality of your state variables. Both Fourier and convolutional models use grid-based data to efficiently learn and predict entire domains in one forward pass, which is in contrast to the pointwise predictions of standard PINN approaches. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5e9360",
   "metadata": {},
   "source": [
    "### Step 4: Adding the Validator\n",
    "\n",
    "The validation data is then added to the domain using `GridValidator` which should be used when dealing with structured data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904d0401",
   "metadata": {},
   "source": [
    "```python\n",
    "    # add validator\n",
    "    val = GridValidator(\n",
    "        nodes,\n",
    "        dataset=test_dataset,\n",
    "        batch_size=cfg.batch_size.validation,\n",
    "        plotter=GridValidatorPlotter(n_examples=5),\n",
    "    )\n",
    "    domain.add_validator(val, \"test\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e16a60",
   "metadata": {},
   "source": [
    "### Step 5: Hydra configuration \n",
    "\n",
    " Let's have a quick look at the configuration for this problem. The configuration for this problem is fairly standard within PhysicsNeMo. A specific FNO architecture is defined for this example inside of the config file. These settings were derived through an automated hyper-parameter sweep using Hydra multirun. The most important parameter for the FNO models is the <code>dimension</code>, which tells PhysicsNeMo to load a 1D, 2D or 3D FNO architecture. <code>nr_fno_layers</code> are the number of Fourier convolution layers in the model, and <code>fno_layer_size</code> is the size of the latent embedded features inside the model. The contents of the <a href=\"../../source_code/darcy/conf/config_FNO.yaml\" rel=\"nofollow\"><code>config_FNO.yaml</code></a> are shown below. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae43f05",
   "metadata": {},
   "source": [
    "```yaml\n",
    "defaults :\n",
    "  - physicsnemo_default\n",
    "  - /arch/conv_fully_connected_cfg@arch.decoder\n",
    "  - /arch/fno_cfg@arch.fno\n",
    "  - scheduler: tf_exponential_lr\n",
    "  - optimizer: adam\n",
    "  - loss: sum\n",
    "  - _self_\n",
    "\n",
    "arch:\n",
    "  decoder:\n",
    "    input_keys: [z, 32]\n",
    "    output_keys: sol\n",
    "    nr_layers: 1\n",
    "    layer_size: 32\n",
    "\n",
    "  fno:\n",
    "    input_keys: coeff\n",
    "    dimension: 2\n",
    "    nr_fno_layers: 4\n",
    "    fno_modes: 12\n",
    "    padding: 9\n",
    "\n",
    "scheduler:\n",
    "  decay_rate: 0.95\n",
    "  decay_steps: 1000\n",
    "\n",
    "training:\n",
    "  rec_results_freq : 1000\n",
    "  max_steps : 10000\n",
    "\n",
    "batch_size:\n",
    "  grid: 32\n",
    "  validation: 32\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98317091",
   "metadata": {},
   "source": [
    "### Step 6: Solver and Training the Model \n",
    "\n",
    "We can create a solver by using the domain we just created along with the other configurations that define the optimizer choices, and settings using PhysicsNeMo’ `Solver` class. The solver can then be executed using the solve method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5d78e6",
   "metadata": {},
   "source": [
    "```python\n",
    "    # make solver\n",
    "    slv = Solver(cfg, domain)\n",
    "\n",
    "    # start solver\n",
    "    slv.solve()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92d2364",
   "metadata": {},
   "source": [
    "Before we can start training, we can make use of Tensorboard for visualizing the loss values and convergence of several other monitors we just created. This can be done inside the Jupyter framework by selecting the directory in which the checkpoint will be stored by clicking on the small checkbox next to it. The option to launch a Tensorboard then shows up in that directory. Once you open Tensorboard, switch between the SCALARS , IMAGES , TEXT , TIME SERIES to visualise and view Validation and other information related to Training.\n",
    "\n",
    "\n",
    "For this application, please verify if you are inside the `/jupyter_notebook/Operators` folder after launching Tensorboard.\n",
    "\n",
    "1. The option to launch a Tensorboard then shows up in that directory.\n",
    "\n",
    "<center><img src=\"../projectile/images/tensorboard.png\" alt=\"Drawing\" style=\"width:900px\" /></center>\n",
    "\n",
    "2. We can launch tensorboard using the following command: \n",
    "\n",
    "```\n",
    "tensorboard --logdir /workspace/python/jupyter_notebook/ --port 8889\n",
    "```\n",
    "\n",
    "3. Open a new tab in your browser and head to [http://127.0.0.1:8889](http://127.0.0.1:8889) . You should see a screen similar to the below one. \n",
    "\n",
    "<center><img src=\"../projectile/images/tensorboard_browser.png\" alt=\"Drawing\" style=\"width:900px\" /></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baecb6f3",
   "metadata": {},
   "source": [
    "The training for the problem can be simply started by executing the python script similar to the examples we saw earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aefcf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"RANK\"]=\"0\"\n",
    "os.environ[\"WORLD_SIZE\"]=\"1\"\n",
    "os.environ[\"MASTER_ADDR\"]=\"localhost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db766351",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../../source_code/darcy/darcy_FNO_lazy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd442ae6",
   "metadata": {},
   "source": [
    "### Visualizing the solution\n",
    "\n",
    "The checkpoint directory is saved based on the results recording frequency specified in the `rec_results_freq` parameter of its derivatives. The network directory folder contains several plots of different validation predictions. Several are shown below, and you can see that the model is able to accurately predict the pressure field for permeability fields it had not seen previously. \n",
    "\n",
    "FNO validation predictions. (Left to right) Input permeability, true pressure, predicted pressure, error. \n",
    "\n",
    "<center><img src=\"images/fno_darcy_pred1.png\" alt=\"Drawing\" style=\"width: 900px;\"/></center>\n",
    "<center><img src=\"images/fno_darcy_pred2.png\" alt=\"Drawing\" style=\"width: 900px;\"/></center>\n",
    "<center><img src=\"images/fno_darcy_pred3.png\" alt=\"Drawing\" style=\"width: 900px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb723cb8",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "Don't forget to check out additional [Open Hackathons Resources](https://www.openhackathons.org/s/technical-resources) and join our [OpenACC and Hackathons Slack Channel](https://www.openacc.org/community#slack) to share your experience and get more help from the community.\n",
    "\n",
    "---\n",
    "\n",
    "# Licensing\n",
    "\n",
    "Copyright © 2023 OpenACC-Standard.org.  This material is released by OpenACC-Standard.org, in collaboration with NVIDIA Corporation, under the Creative Commons Attribution 4.0 International (CC BY 4.0). These materials may include references to hardware and software developed by other entities; all applicable licensing and copyrights apply."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
